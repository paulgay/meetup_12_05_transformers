# Introduction aux transformeurs

Ce github fait partie du matériel qui sera présenté au meetup de machine learning de Pau le 12 mai 2021. 

Il contient deux notebooks : 

- Géneration de texte, tokenization et calcul d'embedding
Ce notebook utilise la librairie Huggingface afin de tester les capacités de génération des transformeurs, ainsi que leur biais.

- Classification de texte avec un (petit) transformeur. 
Ce notebook s'inspire des tutoriels de tensorflow et fournit un code complet implémentant les équations du modèle d'attention. 

## Dépendances 

- Tensorflow 
- Pytorch (pour le modèle CamemBert, qui ne semble pas accessible depuis tensorflow.) 
- transformers (huggingface)
